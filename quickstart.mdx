---
title: "Quickstart"
description: "Get traces flowing from your AI agents in under 5 minutes"
---

This guide walks you through installing the Arzule SDK and capturing your first traces from your agent application.

## Prerequisites

- Python 3.10 or higher
- An agent framework (Claude Code, CrewAI, LangGraph, or AutoGen)
- An Arzule account with API credentials (for cloud mode), or use [local mode](#local-development) to get started without an account

## Step 1: Install the SDK

<CodeGroup>
```bash pip
pip install arzule-ingest
```

```bash poetry
poetry add arzule-ingest
```

```bash uv
uv add arzule-ingest
```
</CodeGroup>

<Note>
The core package includes Claude Code support. For framework integrations, add the appropriate extras:
- **CrewAI**: `pip install arzule-ingest[crewai]`
- **LangGraph/LangChain**: `pip install arzule-ingest[langchain]`
- **AutoGen**: `pip install arzule-ingest[autogen]`
- **Self-hosted server**: `pip install arzule-ingest[server]`
- **All frameworks**: `pip install arzule-ingest[all]`
</Note>

### Upgrading

To upgrade to the latest version:

<CodeGroup>
```bash pip
pip install --upgrade arzule-ingest
```

```bash poetry
poetry update arzule-ingest
```

```bash uv
uv add --upgrade arzule-ingest
```
</CodeGroup>

## Step 2: Set environment variables

The SDK supports multiple deployment modes. Choose the one that fits your needs:

<Tabs>
  <Tab title="Cloud (Production)">
    Send traces to Arzule cloud. Find your credentials in your [Arzule dashboard settings](https://app.arzule.com/dashboard/settings).

    ```bash
    export ARZULE_API_KEY="your-api-key"
    export ARZULE_TENANT_ID="your-tenant-id"
    export ARZULE_PROJECT_ID="your-project-id"
    ```
  </Tab>
  <Tab title="Local (Development)">
    Store traces locally without any cloud setup. Great for getting started or offline development.

    ```bash
    export ARZULE_MODE="local"
    # Optional: customize storage path (default: ~/.arzule/traces/)
    export ARZULE_OUTPUT_PATH="./traces/"
    ```
  </Tab>
  <Tab title="Self-Hosted">
    Send traces to your own backend server.

    ```bash
    export ARZULE_MODE="selfhosted"
    export ARZULE_SELFHOSTED_ENDPOINT="http://localhost:8080/ingest"
    # Optional: add authentication
    export ARZULE_AUTH_TYPE="bearer"
    export ARZULE_AUTH_VALUE="your-token"
    ```

    See the [Self-Hosting Guide](/configuration/self-hosting) for running your own trace server.
  </Tab>
</Tabs>

## Step 3: Initialize and run

<Tabs>
  <Tab title="Claude Code">
    For Claude Code, use the CLI to configure and install hooks. Choose between **global** (all projects) or **project-level** (recommended) setup:

    <Tabs>
      <Tab title="Project-Level (Recommended)">
        Project-level setup keeps configuration isolated per-project. Each project gets its own hooks and credentials.

        ```bash
        # One-time: Configure global credentials (stored in ~/.arzule/config)
        arzule configure

        # Per-project: Initialize hooks and copy config to project
        cd your-project
        arzule init
        ```

        This creates:
        - `.claude/settings.local.json` — Claude Code hooks
        - `.arzule/config` — Project-specific credentials (copied from global)

        <Tip>
        Add `.arzule/` to your `.gitignore` to avoid committing credentials.
        </Tip>
      </Tab>
      <Tab title="Global">
        Global setup applies to all projects. Simpler, but all traces go to the same Arzule project.

        ```bash
        # Configure credentials globally
        arzule configure

        # Install hooks globally
        arzule claude install
        ```
      </Tab>
    </Tabs>

    That's it. Use Claude Code normally and traces are captured automatically with each turn.

    <Tip>
    **Tip:** Run `arzule claude status` to verify hooks are installed correctly.
    </Tip>
  </Tab>
  <Tab title="CrewAI">
    First, install with CrewAI support: `pip install arzule-ingest[crewai]`

    Then add two lines to your `main.py` file - import and init:

    ```python {3,4,21}
    #!/usr/bin/env python
    # src/research_crew/main.py
    import arzule_ingest
    arzule_ingest.init()

    import os
    from research_crew.crew import ResearchCrew

    os.makedirs('output', exist_ok=True)

    def run():
        inputs = {
            'topic': 'Artificial Intelligence in Healthcare'
        }

        # Traces are captured automatically
        result = ResearchCrew().crew().kickoff(inputs=inputs)

        print("\n\n=== FINAL REPORT ===\n\n")
        print(result.raw)
        arzule_ingest.shutdown()

    if __name__ == "__main__":
        run()
    ```

    That's it - run `crewai run` as usual and traces flow to Arzule automatically.

    <Tip>
    **Tip:** Setting `allow_delegation=True` on your agents produces cleaner traces and better visualizations. When agents can delegate tasks to each other, Arzule captures these handoffs clearly, giving you a much more readable graph of agent interactions.
    </Tip>
  </Tab>
  {/* <Tab title="LangChain">
    Add two lines at the top of your script - import and get the callback handler:

    ```python {1,2,12,14}
    import arzule_ingest
    handler = arzule_ingest.langchain.instrument_langchain()

    from langchain_openai import ChatOpenAI
    from langchain_core.prompts import ChatPromptTemplate

    llm = ChatOpenAI(model="gpt-4")
    prompt = ChatPromptTemplate.from_template("Tell me about {topic}")
    chain = prompt | llm

    # Pass the handler to capture traces
    result = chain.invoke({"topic": "AI safety"}, config={"callbacks": [handler]})

    arzule_ingest.shutdown()
    ```
  </Tab> */}
  <Tab title="LangGraph">
    First, install with LangChain support: `pip install arzule-ingest[langchain]`

    Then add two lines at the top of your script - import and get the callback handler:

    ```python {1,2,22,24}
    import arzule_ingest
    handler = arzule_ingest.langgraph.instrument_langgraph()

    from langgraph.graph import StateGraph
    from langchain_openai import ChatOpenAI
    from typing import TypedDict

    class State(TypedDict):
        messages: list
        response: str

    llm = ChatOpenAI(model="gpt-4")

    def chatbot(state: State) -> dict:
        response = llm.invoke(state["messages"])
        return {"response": response.content}

    graph = StateGraph(State)
    graph.add_node("chatbot", chatbot)
    graph.add_edge("__start__", "chatbot")
    compiled = graph.compile()

    # Pass the handler to capture traces
    result = compiled.invoke({"messages": [("user", "Hello!")]}, config={"callbacks": [handler]})

    arzule_ingest.shutdown()
    ```

    <Tip>
    **Tip:** For multi-agent graphs, use `Command(goto="agent_name")` or state-based routing with `next_agent` to get automatic handoff tracking between agents.
    </Tip>
  </Tab>
  <Tab title="AutoGen">
    First, install with AutoGen support: `pip install arzule-ingest[autogen]`

    Then add two lines at the top of your script - import and instrument:

    ```python {1,2,13}
    import arzule_ingest
    arzule_ingest.autogen.instrument_autogen()

    import os
    from autogen import AssistantAgent, UserProxyAgent

    llm_config = {"config_list": [{"model": "gpt-4", "api_key": os.environ.get("OPENAI_API_KEY")}]}
    assistant = AssistantAgent("assistant", llm_config=llm_config)
    user_proxy = UserProxyAgent("user_proxy", code_execution_config=False)

    # Traces are captured automatically
    user_proxy.initiate_chat(assistant, message="Tell me a joke about AI.")
    arzule_ingest.shutdown()
    ```

    <Tip>
    **Note:** AutoGen v0.7+ (AG2) is auto-instrumented when you call `arzule_ingest.init()`. The explicit `instrument_autogen()` call shown above is for AutoGen v0.2.x.
    </Tip>
  </Tab>
</Tabs>

<Tip>
**About `shutdown()`**: Call `arzule_ingest.shutdown()` at the end of your script to ensure all events are flushed to Arzule. While `shutdown()` is registered with `atexit` and runs automatically on normal process exit, calling it explicitly guarantees events are sent before the script continues - especially important if your process might exit abnormally or you're running multiple agents in one script.
</Tip>

## Step 4: View your traces

Open your [Arzule dashboard](https://app.arzule.com/dashboard/overview) to see the captured traces. You'll see:

- The complete execution timeline
- Each agent's actions and decisions
- Tool calls with inputs and outputs
- LLM requests and responses

## Local development

During development, use local mode to store traces without cloud setup:

```bash
export ARZULE_MODE="local"
```

Then use `arzule_ingest.init()` as normal - traces are stored in `~/.arzule/traces/` by default:

```python
import arzule_ingest
arzule_ingest.init()  # Automatically uses local file storage

# Your agent code here - traces are captured automatically
```

View traces with the CLI:

```bash
# List recent trace files
ls ~/.arzule/traces/

# View a specific trace
arzule view ~/.arzule/traces/run_abc123.jsonl
```

<Tip>
You can customize the storage path with `ARZULE_OUTPUT_PATH` or start a local server with `arzule-server` for a more production-like setup. See [Self-Hosting](/configuration/self-hosting) for details.
</Tip>

## Next steps

<CardGroup cols={2}>

<Card title="Self-Hosting" icon="server" href="/configuration/self-hosting">
  Run your own trace server or use local storage.
</Card>

<Card title="Claude Code Integration" icon="terminal" href="/integrations/claude-code">
  Full Claude Code instrumentation guide.
</Card>

<Card title="CrewAI Integration" icon="users" href="/integrations/crewai">
  Full CrewAI instrumentation guide.
</Card>

<Card title="LangGraph Integration" icon="diagram-project" href="/integrations/langgraph">
  Full LangGraph instrumentation guide.
</Card>

<Card title="AutoGen Integration" icon="robot" href="/integrations/autogen">
  Full AutoGen instrumentation guide.
</Card>

<Card title="Environment Variables" icon="gear" href="/configuration/environment-variables">
  Full configuration reference.
</Card>

</CardGroup>
